{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9174deca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T04:56:45.194858Z",
     "start_time": "2021-08-25T04:56:43.737274Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1a75a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T04:56:55.571140Z",
     "start_time": "2021-08-25T04:56:55.547453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3652bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T04:57:10.100405Z",
     "start_time": "2021-08-25T04:57:10.075053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import konlpy\n",
    "konlpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f6cea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T04:59:29.112362Z",
     "start_time": "2021-08-25T04:59:29.103366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908cdb80",
   "metadata": {},
   "source": [
    "## 불용어 파일 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1a48937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:47:21.811640Z",
     "start_time": "2021-08-23T07:47:21.788166Z"
    }
   },
   "outputs": [],
   "source": [
    "features = 5000\n",
    "file_path = './data/stopwords.txt'\n",
    "with open(file_path,'r') as op:\n",
    "    stopwords = op.readlines()\n",
    "    stopwords = stopwords[0].split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6f374",
   "metadata": {},
   "source": [
    "### 단어 추출을 위한 tokenizer  \n",
    "불용어 제거, 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9089f248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:47:22.811951Z",
     "start_time": "2021-08-23T07:47:22.794145Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    okt = Okt()\n",
    "    re.sub('[\\W]',' ',text) # 한글 제외하고 전부 삭제\n",
    "    result = []\n",
    "    token_pos = okt.pos(text)\n",
    "    for word, pos in token_pos:\n",
    "        if (pos == 'Noun') and not(word in stopwords): # 명사 추출, 불용어제거\n",
    "            result.append(str(word))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0c3d3",
   "metadata": {},
   "source": [
    "## 감성사전 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict():\n",
    "    # 데이터 전처리\n",
    "    data = pd.read_csv('./Data/labeling_data.csv',encoding='cp949')\n",
    "    x = data['내용'].astype('str')\n",
    "    y = data['label']\n",
    "\n",
    "    # tf-idf 구축\n",
    "    tfidf = TfidfVectorizer(max_features=features,tokenizer=tokenizer)\n",
    "    x_tdm = tfidf.fit_transform(x)\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_tdm,y,\n",
    "                                                       test_size=0.3,\n",
    "                                                       random_state=42)\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr_clf = LogisticRegressionCV(max_iter=1000)\n",
    "    lr_clf.fit(x_train,y_train)\n",
    "\n",
    "    pred =lr_clf.predict(x_test)\n",
    "\n",
    "    # 회귀에서 각 단어당 회귀계수 추출\n",
    "    st_df = pd.DataFrame({'단어':tfidf.get_feature_names(),\n",
    "                          '회귀계수':lr_clf.coef_.flat})\n",
    "    st_df.tail()\n",
    "    \n",
    "    # 회귀계수가 음수일 때는 -1~0 으로 min-max scaling 변형\n",
    "    st_neg = st_df[st_df['회귀계수']<0].sort_values('회귀계수')\n",
    "    ma = st_neg['회귀계수'].max()\n",
    "    mi = st_neg['회귀계수'].min()\n",
    "    st_neg['points']=st_neg['회귀계수'].apply(lambda x : ((x - mi)/(ma - mi) - 1))\n",
    "\n",
    "    # 회귀계수가 양수인 경우는 0~1로 min-max scaling 변형\n",
    "    st_pos = st_df[st_df['회귀계수']>0].sort_values('회귀계수',ascending=False)\n",
    "    ma = st_pos['회귀계수'].max()\n",
    "    mi = st_pos['회귀계수'].min()\n",
    "    st_pos['points']=st_pos['회귀계수'].apply(lambda x : ((x - mi)/(ma - mi)))\n",
    "\n",
    "    st_df = st_pos.append(st_neg)\n",
    "    st_df.to_csv('./data/dict.csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40566c0b",
   "metadata": {},
   "source": [
    "tf-idf 구축"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
